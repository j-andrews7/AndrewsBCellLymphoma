---
title: Analyzing RNA-seq data
author:
- name: Jared Andrews
  email: jared.andrews07@gmail.com
  affiliation: Washington University School of Medicine, Department of Laboratory and Genomic Medicine
date: "Revised: Ocotober 28th, 2019"
output:
  BiocStyle::html_document:
    toc_float: true
vignette: >
  %\VignetteIndexEntry{1. Analyzing RNA-seq data}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}  
---

```{r, echo=FALSE, results="hide", message=FALSE}
knitr::opts_chunk$set(error=FALSE, message=TRUE, warning=TRUE, eval=FALSE)
library(BiocStyle)
```

# Introduction

This vignette walks through analysis of the B cell lymphoma RNA-seq data included in the future Andrews et al. (2019, your favorite journal with an impact factor > 30) paper.
It uses the convenience functions included in this [package](https://github.com/j-andrews7/OneLinerOmics) to streamline the process.

Several command line tools as well as python are also utilized - each code block should indicate whether it is `bash`, `R`, or `python` code. 
If your system is set up properly, you can still [run many of these code chunks in Rmarkdown files within RStudio](https://bookdown.org/yihui/rmarkdown/language-engines.html), assuming you have all of the software installed.

Some of this code is best ran on a computing cluster, as it takes a significant amount of time locally.
Such instances will have `- cluster` appended to the language statement at the beginning of the code block.

Required Software:

* R (3.6+)
* python3
* [salmon (v0.14+)](https://combine-lab.github.io/salmon/)
* [bedtools](https://bedtools.readthedocs.io/en/latest/) - only needed if generating salmon decoy transcriptome
* [mashmap](https://github.com/marbl/MashMap) - only needed if generating salmon decoy transcriptome
* [STAR](https://github.com/alexdobin/STAR) - only needed if generating tracks
* [deeptools](https://deeptools.readthedocs.io/en/latest/index.html) - only needed if generating tracks

# FAQs/Suggested Reading

That is, if you ask me one of the following questions and haven't read/tried these first, I'm going to tell you to read/try them.

* "How do I tweak (x) part of the analysis?"
	* Read the [rnaseqGene](http://master.bioconductor.org/packages/release/workflows/vignettes/rnaseqGene/inst/doc/rnaseqGene.html) workflow, which walks through a DESeq2 analysis in great detail.
	* Read the [DESeq2 vignette](https://bioconductor.org/packages/release/bioc/vignettes/DESeq2/inst/doc/DESeq2.html#standard-workflow).
* "How does the design formula work?"
	* Read [this chapter](https://cran.r-project.org/doc/manuals/R-intro.html#Statistical-models-in-R) on statistical models in R, which explains linear models and formulae relatively clearly.

## Generating gene counts

This requires R, salmon v0.14, and DESeq2 (along with a few other packages). 
I'm using hg19, but you can supply newer annotations if you want. 
`salmon` needs `mashmap` and `bedtools` as well if generating "decoy-aware" transcriptomes. 

### Create decoy reference transcriptome

Newer versions of salmon recommend using a *decoy-aware* transcriptome to generate the index file to be used for selective alignment.
This process is a bit annoying, so the authors have pre-computed some [decoy transcriptomes](https://drive.google.com/drive/folders/14VqSdZAKH82QwDWhMXNLFqMoskoqv3fS) for hg19 and hg38 with different annotations.
In this case, I used the [GENCODE v31 annotations](ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_31/GRCh37_mapping/) that had been lifted over to hg19, so I had to generate them myself.

> **This had to be run on a cluster with 128 GB RAM. If you can avoid this step by using their pre-generated decoys, I recommend doing so.**

My data is already in folders and all, so some of the paths are kinda inefficient, but I really don't care.
This is needed to create the index for `salmon`.
Using GENCODE v31 annotations/sequences that have been mapped back to GRCh37 (hg19).

```{bash dl-annotations, eval=FALSE}
# bash
mkdir -p RNA_seq/ref

# annotations
wget ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_31/GRCh37_mapping/gencode.v31lift37.annotation.gtf.gz
mv gencode.v31lift37.annotation.gtf.gz ./RNA_Seq/ref/gencode.v31lift37.annotation.gtf.gz
gunzip ./RNA_seq/ref/gencode.v31lift37.annotation.gtf.gz

# transcriptome
wget ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_31/GRCh37_mapping/gencode.v31lift37.transcripts.fa.gz
mv gencode.v31lift37.transcripts.fa.gz ./RNA_Seq/ref/gencode.v31lift37.transcripts.fa.gz
gunzip ./RNA_seq/ref/gencode.v31lift37.transcripts.fa.gz

# genome
wget ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_31/GRCh37_mapping/GRCh37.primary_assembly.genome.fa.gz
mv GRCh37.primary_assembly.genome.fa.gz ./RNA_Seq/ref/GRCh37.primary_assembly.genome.fa.gz
gunzip ./RNA_seq/ref/GRCh37.primary_assembly.genome.fa.gz
```

Download the script to generate the decoys.

```{bash dl-decoy, eval=FALSE}
# bash
# Script for generating decoy genome.
wget https://raw.githubusercontent.com/COMBINE-lab/SalmonTools/master/scripts/generateDecoyTranscriptome.sh
```

This script crashed a lot for me, so I ended up editing it to just snag the last 10 commands or so (those with the step comments) and removing the variable parsing at the beginning, as it uses some deprecated linux commands (`readpath`) that I couldn't install on our computing cluster.

```{bash salmon-decoy, eval=FALSE}
# bash
bash generateDecoyTranscriptome.sh -j 2 -a ./RNA_Seq/ref/gencode.v31lift37.annotation.gtf \
-g ./RNA_Seq/ref/GRCh37.primary_assembly.genome.fa -t ./RNA_Seq/ref/gencode.v31lift37.transcripts.fa \
-o ./RNA_Seq/ref/decoys/
```

### Index the transcriptome

This will generate the *decoy-aware* transcriptome index for our annotations.

```{bash salmon-index, eval=FALSE}
# Bash
# Now actually create the index for salmon. We lower k as some of our samples use 50 bp reads.
salmon index -t ./RNA_Seq/ref/decoys/gentrome.fa -i ./RNA_Seq/ref/gencodev31_grch37_index \
--decoys ./RNA_Seq/ref/decoys/decoys.txt -k 25 --gencode
```

### Quantify
Actually generate the gene counts now. 

```{bash salmon-quant, eval=FALSE}
# bash
for f in ./RNA_Seq/FASTQs/*; do
    samp="${f##*/}"
    count=$(ls -1 "$f" | wc -l)
    echo "$count"
    if [ $count -gt 1 ]
    then
        salmon quant --validateMappings --threads 2 --seqBias -l A -1 "$f"/"$samp"_1.fq.gz \
        -2 "$f"/"$samp"_2.fq.gz -o ./RNA_Seq/quants/"$samp" --index ./RNA_Seq/ref/gencodev31_grch37_index
    else
        salmon quant --validateMappings --threads 2 --seqBias -l A -r "$f"/"$samp".RNA.fq.gz \
        -o ./RNA_Seq/quants/"$samp" --index ./RNA_Seq/ref/gencodev31_grch37_index
    fi
done
```

### Check Mapping Rates

An easy diagnostic to ensure everything worked properly is just to check the mapping rates for each sample. 
Depending on the experimental setup and annotations, a mapping rate of 50-90% may be expected.
Really low rates (<40% or so) are worrying, and such samples should be removed from the analysis if possible.

```{bash}
for f in ./RNA_Seq/quants/*; do
  echo "${f##*/}";
  grep "Mapping rate" "$f"/logs/salmon_quant.log;
done
```

### Make Transcript-to-Gene Mappings
For gene-level summarization and readability.

```{python tx2gene, eval=FALSE}
# python
outter = open("./RNA_Seq/ref/tx2gene.txt", "w")
with open("./RNA_Seq/ref/gencode.v31lift37.transcripts.fa") as f:
    for line in f:
        if not line.startswith(">"):
            continue
        line = line.strip().strip(">").split("|")
        tx = line[0]
        symb = line[5]
        out = "\t".join([tx, symb])
        print(out, file = outter)

outter.close()
```

## Analysis with R

Install this package if you haven't already with `devtools::install_github("j-andrews7/OneLinerOmics")`.
If you don't have `devtools`, it can be installed with `install.packages("devtools")`.

```{r load, eval=TRUE}
# R
suppressPackageStartupMessages(library(OneLinerOmics))
```

The only thing you need now is a sample sheet, which is just a table with sample names and metadata columns. 
We can take a peek at the sample sheet I'm using so he can see how they're constructed. 
It can include as many metadata columns as you'd like.

```{r samplesheet, eval=FALSE}
# R
# Basic sample sheet.
samples <- read.table("./RNA_Seq/Samples.pairedCLL.txt", header=TRUE, sep = "\t")
head(samples, 10)
```

### Run DESeq2

DESeq2 is a very popular R package for performing differential expression analysis.
Raw RNA-seq counts follow a negative binomial distribution, which is how DESeq2 models the data.
It is quick, flexible, and generally works quite well with little to no parameter tweaking.
It can also model technical or batch effects, mitigating their impact on the analysis. 

All of these samples are 150 bp, paired-end sequencing (as shown in the 'lib' column of the sample sheet).
If we had a batch effect or confounding factor we wanted to try to model, we would feed the column name containing it to the `block` argument.
To see the full range of options for the analysis, use `?RunDESeq2`.

```{r run-deseq2, EVAL=FALSE}
# R
mydata <- RunDESeq2(outpath = "./RNA_Seq/Final_Analyses/pairedCLL", quants.path = "./RNA_Seq/quants", 
          samplesheet = "./RNA_Seq/Samples.pairedCLL.txt", tx2gene = "./RNA_Seq/ref/tx2gene.txt",
          level = "disease", padj.thresh = c(0.05, 0.01, 0.001), 
          plot.annos = c("disease", "disease.sub"), count.filt = 50)
```

### Next Steps

Explore the plots, tables, enrichments, etc.
Yes, that's pretty much it.
Re-run if necessary, tweaking parameters as you see fit. 

`mydata` contains everything necessary to re-run visualizations via `ProcessDEGs`, which is quicker if you don't want to read all the gene counts and perform the exporatory data analysis again.

## Alignment & Creating Tracks

Using a pseudoalignment-based quantification method is nice because it avoids the time-consuming headache of alignment and track generation, saving a lot of time and storage space.

If you're _really_ set on this, something like the following shows how to do so (for single-end reads). 
Paired-end is similar, you just need to tweak things to provide the second reads file to `--readFilesIn`.

> STAR requires a lot of memory (>32 GB), so running locally is really not recommended. Utilize a computing cluster/cloud.

In this case, I use [GENCODE annotations](https://www.gencodegenes.org/human/release_19.html), which provide necessary information for handling gapped-reads spanning splice-junctions (less important here, but critical if attempting de novo transcript discovery).

```{bash make_tracks, eval=FALSE}
# bash-cluster

# Create index.
STAR --runThreadN 8 --runMode genomeGenerate --genomeDir ./STAR_Index \
--genomeFastaFiles ./Homo_sapiens.GRCh37.75.dna.primary_assembly.fa \
--sjdbGTFfile ./gencode.v19.annotation.gtf

# Align gzipped FASTQs.
for f in *.gz; do
  STAR --runThreadN 8 --runMode alignReads --outFilterMultimapNmax 20 \
  --alignSJoverhangMin 8 --alignSJDBoverhangMin 1 --alignIntronMin 20 \
  --alignIntronMax 1000000 --outFilterMismatchNmax 999 \
  --readFilesCommand gunzip -c --genomeDir ./STAR_Index \
  --outSAMtype BAM SortedByCoordinate --readFilesIn "$f" \
  --outFileNamePrefix ${f%%.RNA*};
done

# Change --effectiveGenomeSize if using hg38 or different organism.
for f in *.bam; do 
	echo "$f"; 
	samtools index "$f";
	bamCoverage --bam "$f" -o "$f".rpkm.bw --binSize 10 \
	--ignoreForNormalization chrX chrM chrY --normalizeUsing RPKM \
	-p 8 --effectiveGenomeSize 2864785220; 
done
```

Happy? Now you can view the `bigWig` files on UCSC by using a [track hub](https://genome.ucsc.edu/goldenPath/help/hgTrackHubHelp.html) if you have a publicly accessible location to put the files.

# Session Information

```{r session, eval=TRUE}
sessionInfo()
```
